#!/usr/bin/env python3
# -*- coding: utf-8 -*-
'''
average models (not snapshot) generated by espnet2.
'''

import argparse
import json
import os
import logging

import numpy as np
import torch


def main():
    last = args.models
    print("average over", last)
    avg = None

    # sum
    for path in last:
        states = torch.load(path, map_location=torch.device("cpu"))
        if "model" in states: 
            states = states["model"]
        if avg is None:
            avg = states
        else:
            for k in avg.keys():
                avg[k] += states[k]

    num = len(last)
    if num > 1:
        for k in avg:
            if  str(avg[k].dtype).startswith("torch.int"):
                # For int type, not averaged, but only accumulated.
                # e.g. BatchNorm.num_batches_tracked
                # (If there are any cases that requires averaging
                #  or the other reducing method, e.g. max/min, for integer type,
                #  please report.)
                logging.info(f"Accumulating {k} instead of averaging")
                pass
            else:
                avg[k] = avg[k] / num

    if args.stats:
        stat = np.load(args.stats)
        mean = stat['sum']/stat['count']
        std = np.sqrt(stat['sum_square']/stat['count'] - mean * mean)
        mean = torch.from_numpy(mean)
        std = torch.from_numpy(std)
        print("stat added", args.stats)

        avg['normalize.mean'] = mean
        avg['normalize.std'] = std

    if args.compat:
        torch.save(avg, args.out, _use_new_zipfile_serialization=False)
    else:
        torch.save(avg, args.out)


def get_parser():
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument("-o", "--out", required=True, type=str)
    parser.add_argument("--compat", action="store_true")
    parser.add_argument("--stats", type = str, default = None)
    parser.add_argument("models", nargs='+', type=str)
    return parser


if __name__ == "__main__":
    args = get_parser().parse_args()
    main()
